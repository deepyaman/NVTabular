

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>NVTabular | API documentation &mdash; NVTabular 2020 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Core Features" href="core_features.html" />
    <link rel="prev" title="Welcome to NVTabular’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> NVTabular
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#benefits">Benefits</a></li>
<li class="toctree-l2"><a class="reference internal" href="#core-features">Core Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#installing-nvtabular-using-conda">Installing NVTabular Using Conda</a></li>
<li class="toctree-l3"><a class="reference internal" href="#installing-nvtabular-with-the-docker-container">Installing NVTabular with the Docker Container</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples-and-tutorials">Examples and Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="#feedback-and-support">Feedback and Support</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="ETL.html">ETL</a></li>
<li class="toctree-l1"><a class="reference internal" href="training/index.html">Accelerated Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources/index.html">Resources</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NVTabular</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>NVTabular | API documentation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="nvtabular-api-documentation">
<h1><a class="reference external" href="https://github.com/NVIDIA/NVTabular">NVTabular</a> | <a class="reference external" href="https://nvidia.github.io/NVTabular/main/index.html">API documentation</a><a class="headerlink" href="#nvtabular-api-documentation" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/NVIDIA/NVTabular">NVTabular</a> is a feature engineering and preprocessing library for tabular data that is designed to quickly and easily manipulate terabyte scale datasets and train deep learning (DL) based recommender systems. It provides a high level abstraction to simplify code and accelerates computation on the GPU using the <a class="reference external" href="https://github.com/rapidsai/cudf/tree/main/python/dask_cudf">RAPIDS Dask-cuDF</a> library. NVTabular is designed to be interoperable with both PyTorch and TensorFlow using dataloaders that we have developed as extensions of native framework code. In our experiments, we were able to speed up existing TensorFlow pipelines by 9 times and existing PyTorch pipelines by 5 times with our highly optimized dataloaders.</p>
<p>NVTabular is a component of <a class="reference external" href="https://developer.nvidia.com/nvidia-merlin"><strong>NVIDIA Merlin Open Beta</strong></a>. NVIDIA Merlin is used for building large-scale deep learning recommender systems, which require massive datasets to train, particularly for deep learning based solutions. With NVTabular being a part of the Merlin ecosystem, it also works with the other Merlin components including <a class="reference external" href="https://github.com/NVIDIA/HugeCTR">HugeCTR</a> and <a class="reference external" href="https://github.com/NVIDIA/tensorrt-inference-server">Triton Inference Server</a> to provide end-to-end acceleration of recommender systems on the GPU. Extending beyond model training, with NVIDIA’s Triton Inference Server, the feature engineering and preprocessing steps performed on the data during training can be automatically applied to incoming data during inference.</p>
<div class="section" id="benefits">
<h2>Benefits<a class="headerlink" href="#benefits" title="Permalink to this headline">¶</a></h2>
<p>Our ultimate goal is faster iteration on massive tabular datasets, both for experimentation during training, and also production model responsiveness. NVTabular is designed to support data scientists and machine learning (ML) engineers train (deep learning) recommender systems and resolve tabular data problems by allowing them to:</p>
<ul class="simple">
<li><p>prepare datasets quickly and easily for experimentation so that more models can be trained.</p></li>
<li><p>process datasets that exceed GPU and CPU memory without having to worry about scale.</p></li>
<li><p>use optimized dataloaders to accelerate training with TensorFlow and PyTorch.</p></li>
<li><p>focus on what to do with the data and not how to do it by using abstraction at the operation level.</p></li>
</ul>
<p>NVTabular also helps ML/Ops engineers with deploying models into production by providing faster dataset transformation. This makes it easy for production models to be trained more frequently and kept up to date, helping improve responsiveness and model performance.</p>
</div>
<div class="section" id="core-features">
<h2>Core Features<a class="headerlink" href="#core-features" title="Permalink to this headline">¶</a></h2>
<p>NVTabular supports the following core features:</p>
<ul class="simple">
<li><p><a class="reference external" href="../docs/source/core_features.md#tensorflow-and-pytorch-interoperability">TensorFlow and PyTorch Interoperability</a></p></li>
<li><p><a class="reference external" href="../docs/source/core_features.md#hugectr-interoperability">HugeCTR Interoperability</a></p></li>
<li><p><a class="reference external" href="../docs/source/core_features.md#multi-gpu-support">Multi-GPU Support</a></p></li>
<li><p><a class="reference external" href="../docs/source/core_features.md#multi-node-support">Multi-Node Support</a></p></li>
<li><p><a class="reference external" href="../docs/source/core_features.md#multi-hot-encoding-and-pre-existing-embeddings">Multi-Hot Encoding and Pre-existing Embeddings</a></p></li>
<li><p><a class="reference external" href="../docs/source/core_features.md#shuffling-datasets">Shuffling Datasets</a></p></li>
</ul>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>To install NVTabular, ensure that you meet the following prerequisites:</p>
<ul class="simple">
<li><p>CUDA version 10.0+</p></li>
<li><p>Python version 3.7+</p></li>
<li><p>NVIDIA Pascal GPU or later</p></li>
</ul>
<p><strong>NOTE</strong>: NVTabular will only run on Linux. Other operating systems are not currently supported.</p>
<div class="section" id="installing-nvtabular-using-conda">
<h3>Installing NVTabular Using Conda<a class="headerlink" href="#installing-nvtabular-using-conda" title="Permalink to this headline">¶</a></h3>
<p>NVTabular can be installed with Anaconda from the <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> channel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">nvidia</span> <span class="o">-</span><span class="n">c</span> <span class="n">rapidsai</span> <span class="o">-</span><span class="n">c</span> <span class="n">numba</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">nvtabular</span> <span class="n">python</span><span class="o">=</span><span class="mf">3.7</span> <span class="n">cudatoolkit</span><span class="o">=</span><span class="mf">10.2</span>
</pre></div>
</div>
</div>
<div class="section" id="installing-nvtabular-with-the-docker-container">
<h3>Installing NVTabular with the Docker Container<a class="headerlink" href="#installing-nvtabular-with-the-docker-container" title="Permalink to this headline">¶</a></h3>
<p>NVTabular is available in the NVIDIA container repository at the following location: http://ngc.nvidia.com/catalog/containers/nvidia:nvtabular. You can pull the container by running the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">run</span> <span class="o">--</span><span class="n">runtime</span><span class="o">=</span><span class="n">nvidia</span> <span class="o">--</span><span class="n">rm</span> <span class="o">-</span><span class="n">it</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8888</span><span class="p">:</span><span class="mi">8888</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8797</span><span class="p">:</span><span class="mi">8787</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8796</span><span class="p">:</span><span class="mi">8786</span> <span class="o">--</span><span class="n">ipc</span><span class="o">=</span><span class="n">host</span> <span class="o">--</span><span class="n">cap</span><span class="o">-</span><span class="n">add</span> <span class="n">SYS_PTRACE</span> <span class="n">nvcr</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">nvidia</span><span class="o">/</span><span class="n">nvtabular</span><span class="p">:</span><span class="mf">0.3</span> <span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">bash</span>
</pre></div>
</div>
<p><strong>NOTE</strong>: If you are running on Docker version 19 and higher, change <code class="docutils literal notranslate"><span class="pre">--runtime=nvidia</span></code> to <code class="docutils literal notranslate"><span class="pre">--gpus</span> <span class="pre">all</span></code>.</p>
<p>The container will open a shell when the run command execution is completed. You’ll have to start jupyter lab on the Docker container. It should look similar to this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="o">@</span><span class="mi">2</span><span class="n">efa5b50b909</span><span class="p">:</span>
</pre></div>
</div>
<ol>
<li><p>Activate the <code class="docutils literal notranslate"><span class="pre">rapids</span></code> conda environment by running the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="o">@</span><span class="mi">2</span><span class="n">efa5b50b909</span><span class="p">:</span> <span class="n">source</span> <span class="n">activate</span> <span class="n">rapids</span>
</pre></div>
</div>
<p>You should receive the following response, indicating that the environment has been activated:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">rapids</span><span class="p">)</span><span class="n">root</span><span class="o">@</span><span class="mi">2</span><span class="n">efa5b50b909</span><span class="p">:</span>
</pre></div>
</div>
</li>
<li><p>Start the jupyter-lab server by running the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">jupyter</span><span class="o">-</span><span class="n">lab</span> <span class="o">--</span><span class="n">allow</span><span class="o">-</span><span class="n">root</span> <span class="o">--</span><span class="n">ip</span><span class="o">=</span><span class="s1">&#39;0.0.0.0&#39;</span> <span class="o">--</span><span class="n">NotebookApp</span><span class="o">.</span><span class="n">token</span><span class="o">=</span><span class="s1">&#39;&lt;password&gt;&#39;</span>
</pre></div>
</div>
</li>
<li><p>Open any browser to access the jupyter-lab server using <MachineIP>:8888.</p></li>
<li><p>Once in the server, navigate to the <code class="docutils literal notranslate"><span class="pre">/nvtabular/</span></code> directory and explore the code base or try out some of the examples.</p>
<p>The container contains the codebase along with all of our dependencies, particularly <a class="reference external" href="https://github.com/rapidsai/cudf/tree/main/python/dask_cudf">RAPIDS Dask-cuDF</a> and a range of <a class="reference external" href="examples/index">examples</a>. The easiest way to get started is to simply launch the container and explore the examples within it. The code base and related examples can be found at the following directory location within the container:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">nvtabular</span><span class="o">/</span>
</pre></div>
</div>
</li>
</ol>
</div>
</div>
<div class="section" id="examples-and-tutorials">
<h2>Examples and Tutorials<a class="headerlink" href="#examples-and-tutorials" title="Permalink to this headline">¶</a></h2>
<p>The following use cases can be found in our <a class="reference external" href="https://nvidia.github.io/NVTabular/main/examples/index.html">API documentation examples section</a>:</p>
<ul class="simple">
<li><p>Preprocessing</p></li>
<li><p>Feature engineering</p></li>
<li><p>Dataloading in Tensorflow, PyTorch, and HugeCTR</p></li>
</ul>
<p>Performance of the Criteo DRLM workflow demonstrates the effectiveness of the NVTabular library. The original ETL script provided in Numpy took over five days to complete. Combined with CPU training, the total iteration time is over one week. By optimizing the ETL code in spark and running on a DGX-1 equivalent cluster, we were able to bring that time down to three hours for ETL and one hour for training.</p>
<p>With NVTabular running on a single V100 32GB GPU, we were able to complete ETL in 13 minutes. With a DGX-1 cluster of eight V100 GPUs, we can accelerate ETL to 3 minutes. Combined with <a class="reference external" href="http://www.github.com/NVIDIA/HugeCTR/">HugeCTR</a>, we can process the dataset and train the full model in only 6 minutes. This fast iteration is the goal of NVTabular and the <a class="reference external" href="https://developer.nvidia.com/nvidia-merlin">Merlin application framework</a>. We’re working on A100 benchmarks and will share them as soon as they are available.</p>
<p>We also have a <a class="reference external" href="examples/rossmann/index">simple tutorial</a> that demonstrates similar functionality on a much smaller dataset. A pipeline for the <a class="reference external" href="https://www.kaggle.com/c/rossmann-store-sales">Rossman store sales dataset</a> that feeds into a <a class="reference external" href="https://docs.fast.ai/tabular.learner.html">fast.ai tabular data model</a> is provided.</p>
</div>
<div class="section" id="feedback-and-support">
<h2>Feedback and Support<a class="headerlink" href="#feedback-and-support" title="Permalink to this headline">¶</a></h2>
<p>If you’d like to contribute to the library directly, please see <a class="reference external" href="https://github.com/NVIDIA/NVTabular/blob/main//CONTRIBUTING.md">Contributing.md</a>. We’re particularly interested in contributions or feature requests for our feature engineering and preprocessing operations. To further advance our Merlin Roadmap, we encourage you to share all the details regarding your recommender system pipeline using this <a class="reference external" href="https://developer.nvidia.com/merlin-devzone-survey">this survey</a>.</p>
<p>If you’re interested in learning more about how NVTabular works under the hood, we’ve provided this <a class="reference external" href="architecture">more detailed description of the core functionality</a>. We also have <a class="reference external" href="https://nvidia.github.io/NVTabular/main/index.html">API documentation</a> that outlines the specifics of the available calls within the library. You can also find public presentations and blog posts under <a class="reference external" href="Resources">Resources</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="core_features.html" class="btn btn-neutral float-right" title="Core Features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to NVTabular’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, NVIDIA

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: main
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../v0.1.0/Introduction.html">v0.1.0</a></dd>
      <dd><a href="../v0.1.1/Introduction.html">v0.1.1</a></dd>
      <dd><a href="../v0.2.0/Introduction.html">v0.2.0</a></dd>
      <dd><a href="../v0.3.0/Introduction.html">v0.3.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="Introduction.html">main</a></dd>
    </dl>
  </div>
</div>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>